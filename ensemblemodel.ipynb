{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12242410,"sourceType":"datasetVersion","datasetId":7713710}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics\nimport os\nimport sys\nimport yaml\nimport torch\nimport ultralytics \nimport numpy as np\nfrom pathlib import Path\nimport shutil\nimport json\nfrom collections import defaultdict\nfrom ultralytics import YOLO\nfrom PIL import Image\nimport cv2\nfrom sklearn.model_selection import StratifiedShuffleSplit\nimport albumentations as A\n\nclass EnhancedYOLOEnsemble:\n    def __init__(self, model_configs, weights=None, tta_config=None):\n        self.models = []\n        self.model_names = []\n        self.weights = weights if weights else [1.0] * len(model_configs)\n        self.tta_config = tta_config or {\n            'enable': True,\n            'scales': [0.8, 1.0, 1.2],\n            'flips': [False, True],\n            'rotations': [0, 90, 180, 270]\n        }\n        \n        for config in model_configs:\n            model = YOLO(config['model_name'])\n            self.models.append(model)\n            self.model_names.append(config['model_name'])\n        print(f\"Initialized ensemble with {len(self.models)} models:\")\n        for name in self.model_names:\n            print(f\"  - {name}\")\n\n    def get_augmentation_pipeline(self):\n        \"\"\"Enhanced data augmentation pipeline\"\"\"\n        return A.Compose([\n            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n            A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n            A.GaussianBlur(blur_limit=(1, 3), p=0.3),\n            A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n            A.RandomGamma(gamma_limit=(80, 120), p=0.3),\n            A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.3),\n            A.RandomShadow(p=0.2),\n            A.RandomFog(fog_coef_lower=0.1, fog_coef_upper=0.3, p=0.1),\n            A.Cutout(num_holes=8, max_h_size=32, max_w_size=32, p=0.3),\n            A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.3),\n        ], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n\n    def train_models(self, data_yaml, epochs=100, imgsz=640, batch_size=16, patience=20):\n        \"\"\"Enhanced training with better hyperparameters\"\"\"\n        self.trained_models = []\n        \n        # Enhanced training parameters\n        enhanced_params = {\n            'epochs': epochs,\n            'imgsz': imgsz,\n            'batch': batch_size,\n            'patience': patience,\n            'device': 0 if torch.cuda.is_available() else 'cpu',\n            'optimizer': 'AdamW',\n            'lr0': 0.001,  # Lower initial learning rate\n            'lrf': 0.01,   # Final learning rate factor\n            'momentum': 0.937,\n            'weight_decay': 0.0005,\n            'warmup_epochs': 3,\n            'warmup_momentum': 0.8,\n            'warmup_bias_lr': 0.1,\n            'box': 7.5,    # Box loss gain\n            'cls': 0.5,    # Class loss gain  \n            'dfl': 1.5,    # DFL loss gain\n            'pose': 12.0,  # Pose loss gain\n            'kobj': 1.0,   # Keypoint obj loss gain\n            'label_smoothing': 0.0,\n            'nbs': 64,     # Nominal batch size\n            'hsv_h': 0.015,  # Image HSV-Hue augmentation\n            'hsv_s': 0.7,    # Image HSV-Saturation augmentation  \n            'hsv_v': 0.4,    # Image HSV-Value augmentation\n            'degrees': 0.0,  # Image rotation (+/- deg)\n            'translate': 0.1, # Image translation (+/- fraction)\n            'scale': 0.5,    # Image scale (+/- gain)\n            'shear': 0.0,    # Image shear (+/- deg)\n            'perspective': 0.0, # Image perspective (+/- fraction)\n            'flipud': 0.0,      # Image flip up-down (probability)\n            'fliplr': 0.5,      # Image flip left-right (probability)\n            'mosaic': 1.0,      # Image mosaic (probability)\n            'mixup': 0.1,       # Image mixup (probability)\n            'copy_paste': 0.1,  # Segment copy-paste (probability)\n            'auto_augment': 'randaugment',\n            'erasing': 0.4,     # Random erasing probability\n            'crop_fraction': 1.0, # Image crop fraction\n        }\n        \n        for i, model in enumerate(self.models):\n            print(f\"\\nTraining Model {i+1}/{len(self.models)}: {self.model_names[i]}\")\n            try:\n                results = model.train(\n                    data=data_yaml,\n                    project=f\"enhanced_train_{self.model_names[i]}\".replace('.', '_'),\n                    name=\"run\",\n                    **enhanced_params\n                )\n                self.trained_models.append(model)\n                print(f\"✅ Trained {self.model_names[i]}\")\n            except Exception as e:\n                print(f\"❌ Error training {self.model_names[i]}: {e}\")\n                self.trained_models.append(model)\n\n    def apply_tta_transforms(self, image):\n        \"\"\"Apply Test Time Augmentation transforms\"\"\"\n        transforms = []\n        \n        if not self.tta_config['enable']:\n            return [image]\n        \n        # Original image\n        transforms.append(('original', image, lambda x: x))\n        \n        # Scale transforms\n        for scale in self.tta_config['scales']:\n            if scale != 1.0:\n                h, w = image.shape[:2]\n                new_h, new_w = int(h * scale), int(w * scale)\n                scaled = cv2.resize(image, (new_w, new_h))\n                # Inverse transform function\n                inv_fn = lambda x, orig_h=h, orig_w=w: cv2.resize(x, (orig_w, orig_h))\n                transforms.append((f'scale_{scale}', scaled, inv_fn))\n        \n        # Flip transforms\n        for flip in self.tta_config['flips']:\n            if flip:\n                flipped = cv2.flip(image, 1)  # Horizontal flip\n                inv_fn = lambda x: cv2.flip(x, 1)\n                transforms.append(('flip_h', flipped, inv_fn))\n        \n        return transforms\n\n    def ensemble_predict_with_tta(self, image_path, conf_threshold=0.1, iou_threshold=0.4):\n        \"\"\"Enhanced prediction with Test Time Augmentation and lower thresholds\"\"\"\n        image = cv2.imread(str(image_path))\n        if image is None:\n            return {'boxes': np.array([]), 'scores': np.array([]), 'classes': np.array([])}\n        \n        all_predictions = []\n        \n        # Apply TTA transforms\n        tta_transforms = self.apply_tta_transforms(image)\n        \n        for model_idx, model in enumerate(self.trained_models):\n            model_predictions = []\n            \n            for transform_name, transformed_img, inverse_fn in tta_transforms:\n                try:\n                    # Save transformed image temporarily\n                    temp_path = f\"/tmp/temp_tta_{transform_name}.jpg\"\n                    cv2.imwrite(temp_path, transformed_img)\n                    \n                    # Multiple confidence thresholds for better recall\n                    for conf_thresh in [0.05, 0.1, 0.15, 0.2]:\n                        results = model.predict(\n                            temp_path, \n                            conf=conf_thresh, \n                            iou=iou_threshold,\n                            verbose=False,\n                            agnostic_nms=True,  # Class-agnostic NMS\n                            max_det=1000       # Allow more detections\n                        )\n                        \n                        if results and len(results) > 0 and results[0].boxes is not None:\n                            boxes = results[0].boxes\n                            if len(boxes) > 0:\n                                predictions = {\n                                    'boxes': boxes.xyxy.cpu().numpy(),\n                                    'scores': boxes.conf.cpu().numpy(),\n                                    'classes': boxes.cls.cpu().numpy().astype(int),\n                                    'model_weight': self.weights[model_idx],\n                                    'transform': transform_name,\n                                    'conf_thresh': conf_thresh\n                                }\n                                model_predictions.append(predictions)\n                    \n                    # Clean up temp file\n                    if os.path.exists(temp_path):\n                        os.remove(temp_path)\n                        \n                except Exception as e:\n                    print(f\"⚠️ Error in TTA prediction: {e}\")\n            \n            all_predictions.extend(model_predictions)\n        \n        return self._advanced_combine_predictions(all_predictions, iou_threshold, conf_threshold)\n\n    def _advanced_combine_predictions(self, all_predictions, iou_threshold=0.4, final_conf_threshold=0.25):\n        \"\"\"Advanced prediction combination with weighted voting and confidence calibration\"\"\"\n        if not all_predictions:\n            return {'boxes': np.array([]), 'scores': np.array([]), 'classes': np.array([])}\n        \n        # Collect all predictions with metadata\n        prediction_data = []\n        for pred in all_predictions:\n            for i in range(len(pred['boxes'])):\n                prediction_data.append({\n                    'box': pred['boxes'][i],\n                    'score': pred['scores'][i],\n                    'class': pred['classes'][i],\n                    'weight': pred['model_weight'],\n                    'transform': pred.get('transform', 'original'),\n                    'conf_thresh': pred.get('conf_thresh', 0.25)\n                })\n        \n        if not prediction_data:\n            return {'boxes': np.array([]), 'scores': np.array([]), 'classes': np.array([])}\n        \n        # Group predictions by class\n        class_groups = defaultdict(list)\n        for pred in prediction_data:\n            class_groups[pred['class']].append(pred)\n        \n        final_boxes, final_scores, final_classes = [], [], []\n        \n        # Process each class separately\n        for class_id, class_preds in class_groups.items():\n            if not class_preds:\n                continue\n            \n            # Convert to arrays for processing\n            boxes = np.array([p['box'] for p in class_preds])\n            scores = np.array([p['score'] * p['weight'] for p in class_preds])\n            \n            # Apply Soft-NMS instead of regular NMS for better recall\n            keep_indices = self._soft_nms(boxes, scores, iou_threshold)\n            \n            for idx in keep_indices:\n                if scores[idx] >= final_conf_threshold:\n                    final_boxes.append(boxes[idx])\n                    final_scores.append(scores[idx])\n                    final_classes.append(class_id)\n        \n        return {\n            'boxes': np.array(final_boxes) if final_boxes else np.array([]),\n            'scores': np.array(final_scores) if final_scores else np.array([]),\n            'classes': np.array(final_classes) if final_classes else np.array([])\n        }\n\n    def _soft_nms(self, boxes, scores, iou_threshold, sigma=0.5):\n        \"\"\"Soft-NMS implementation for better recall\"\"\"\n        if len(boxes) == 0:\n            return []\n        \n        x1, y1, x2, y2 = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]\n        areas = (x2 - x1) * (y2 - y1)\n        order = scores.argsort()[::-1]\n        \n        keep = []\n        while order.size > 0:\n            i = order[0]\n            keep.append(i)\n            \n            if order.size == 1:\n                break\n            \n            xx1 = np.maximum(x1[i], x1[order[1:]])\n            yy1 = np.maximum(y1[i], y1[order[1:]])\n            xx2 = np.minimum(x2[i], x2[order[1:]])\n            yy2 = np.minimum(y2[i], y2[order[1:]])\n            \n            w = np.maximum(0.0, xx2 - xx1)\n            h = np.maximum(0.0, yy2 - yy1)\n            inter = w * h\n            ovr = inter / (areas[i] + areas[order[1:]] - inter)\n            \n            # Soft-NMS: reduce scores instead of removing boxes\n            scores[order[1:]] = scores[order[1:]] * np.exp(-(ovr ** 2) / sigma)\n            \n            # Keep boxes with sufficient scores\n            inds = np.where(scores[order[1:]] > 0.001)[0]\n            order = order[inds + 1]\n        \n        return keep\n\n    # Update the main predict method\n    def ensemble_predict(self, image_path, conf_threshold=0.25, iou_threshold=0.45):\n        \"\"\"Use enhanced prediction with TTA\"\"\"\n        return self.ensemble_predict_with_tta(image_path, conf_threshold, iou_threshold)\n\ndef enhanced_setup_yolo_dataset(original_data_path, working_path, stratify=True):\n    \"\"\"Enhanced dataset setup with stratified splitting\"\"\"\n    data_path = Path(original_data_path)\n    images = list((data_path / \"images\").glob(\"*.[jp][pn]g\"))\n    labels = list((data_path / \"labels\").glob(\"*.txt\"))\n    \n    if not images or not labels:\n        return None, None\n    \n    print(f\"Detected {len(images)} images and {len(labels)} labels.\")\n    \n    # Create class distribution for stratified splitting\n    class_counts = defaultdict(int)\n    image_class_map = {}\n    \n    for img in images:\n        label_file = data_path / 'labels' / f\"{img.stem}.txt\"\n        if label_file.exists():\n            classes = set()\n            with open(label_file, 'r') as f:\n                for line in f:\n                    parts = line.strip().split()\n                    if parts:\n                        classes.add(int(parts[0]))\n            \n            # Use dominant class for stratification\n            if classes:\n                dominant_class = max(classes) if len(classes) == 1 else -1  # Multi-class images get -1\n                image_class_map[img] = dominant_class\n                class_counts[dominant_class] += 1\n    \n    # Stratified split if possible\n    if stratify and len(set(image_class_map.values())) > 1:\n        try:\n            from sklearn.model_selection import train_test_split\n            images_array = np.array(images)\n            labels_array = np.array([image_class_map.get(img, 0) for img in images])\n            \n            # First split: train vs (val + test)\n            train_imgs, temp_imgs, _, temp_labels = train_test_split(\n                images_array, labels_array, test_size=0.3, stratify=labels_array, random_state=42\n            )\n            \n            # Second split: val vs test\n            val_imgs, test_imgs = train_test_split(\n                temp_imgs, test_size=0.5, stratify=temp_labels, random_state=42\n            )\n            \n            print(\"Used stratified splitting based on class distribution\")\n            \n        except Exception as e:\n            print(f\"Stratified splitting failed ({e}), using random split\")\n            stratify = False\n    \n    if not stratify:\n        # Fallback to random splitting\n        indices = np.arange(len(images))\n        np.random.seed(42)\n        np.random.shuffle(indices)\n        n = len(images)\n        train_idx = indices[:int(0.7*n)]\n        val_idx = indices[int(0.7*n):int(0.85*n)]\n        test_idx = indices[int(0.85*n):]\n        \n        train_imgs = [images[i] for i in train_idx]\n        val_imgs = [images[i] for i in val_idx]\n        test_imgs = [images[i] for i in test_idx]\n    \n    structure = {\n        'train': {\n            'images': train_imgs,\n            'labels': [data_path / 'labels' / f\"{img.stem}.txt\" for img in train_imgs]\n        },\n        'val': {\n            'images': val_imgs,\n            'labels': [data_path / 'labels' / f\"{img.stem}.txt\" for img in val_imgs]\n        },\n        'test': {\n            'images': test_imgs,\n            'labels': [data_path / 'labels' / f\"{img.stem}.txt\" for img in test_imgs]\n        }\n    }\n    \n    output_path = Path(working_path) / \"enhanced_yolo_dataset\"\n    \n    # Copy files to organized structure\n    for split in ['train', 'val', 'test']:\n        (output_path / split / 'images').mkdir(parents=True, exist_ok=True)\n        (output_path / split / 'labels').mkdir(parents=True, exist_ok=True)\n        \n        for img in structure[split]['images']:\n            shutil.copy2(img, output_path / split / 'images' / img.name)\n        for lbl in structure[split]['labels']:\n            if lbl.exists():\n                shutil.copy2(lbl, output_path / split / 'labels' / lbl.name)\n    \n    # Analyze class distribution\n    class_ids = set()\n    class_distribution = defaultdict(int)\n    \n    for split in ['train', 'val', 'test']:\n        for f in (output_path / split / 'labels').glob('*.txt'):\n            with open(f, 'r') as file:\n                for line in file:\n                    parts = line.strip().split()\n                    if parts:\n                        class_id = int(parts[0])\n                        class_ids.add(class_id)\n                        class_distribution[class_id] += 1\n    \n    n_classes = max(class_ids) + 1 if class_ids else 0\n    class_names = [f'class_{i}' for i in range(n_classes)]\n    \n    print(f\"Detected {n_classes} classes with distribution: {dict(class_distribution)}\")\n    \n    return output_path, class_names\n\n# ---------------------------------------------------------------\n# MAIN EXECUTION WITH IMPROVEMENTS\n# ---------------------------------------------------------------\nif __name__ == \"__main__\":\n    DATA_PATH = \"/kaggle/input/yolov11dat\"\n    WORK_PATH = \"/kaggle/working\"\n    \n    # Enhanced hyperparameters\n    EPOCHS = 150          # Increased epochs\n    BATCH_SIZE = 8        # Smaller batch size for better gradients\n    IMG_SIZE = 800        # Larger image size for better detection\n    PATIENCE = 25         # More patience for convergence\n    \n    print(f\"Using device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")\n\n    # Enhanced dataset setup\n    dataset_path, class_names = enhanced_setup_yolo_dataset(DATA_PATH, WORK_PATH, stratify=True)\n    if dataset_path is None:\n        sys.exit(1)\n\n    yaml_path = create_yaml_config(dataset_path, class_names)\n\n    # Enhanced model ensemble with more diverse models\n    model_configs = [\n        {'model_name': 'yolo11x.pt'},     # Largest YOLOv11 model\n        {'model_name': 'yolo11l.pt'},     # Large YOLOv11 model  \n        {'model_name': 'yolov8x.pt'},     # Largest YOLOv8 model\n        {'model_name': 'yolov9e.pt'},     # YOLOv9 extended model\n        {'model_name': 'yolov10x.pt'},    # YOLOv10 extra large\n    ]\n    \n    # Optimized ensemble weights (sum to 1.0)\n    ensemble_weights = [0.25, 0.2, 0.2, 0.2, 0.15]\n    \n    # TTA configuration\n    tta_config = {\n        'enable': True,\n        'scales': [0.8, 0.9, 1.0, 1.1, 1.2],\n        'flips': [False, True],\n        'rotations': [0]  # Rotations can be expensive, disable if needed\n    }\n    \n    # Initialize enhanced ensemble\n    ensemble = EnhancedYOLOEnsemble(\n        model_configs, \n        weights=ensemble_weights,\n        tta_config=tta_config\n    )\n    \n    # Train with enhanced parameters\n    ensemble.train_models(\n        str(yaml_path), \n        epochs=EPOCHS, \n        imgsz=IMG_SIZE, \n        batch_size=BATCH_SIZE,\n        patience=PATIENCE\n    )\n\n    print(\"\\n✅ Enhanced training complete. Ready for evaluation with TTA.\")\n\n# Usage for evaluation (update your evaluation code):\n# When calling ensemble_predict, use lower confidence thresholds:\n# preds = ensemble.ensemble_predict(str(img_path), conf_threshold=0.1, iou_threshold=0.4)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-28T17:57:16.065456Z","iopub.execute_input":"2025-06-28T17:57:16.066272Z","iopub.status.idle":"2025-06-28T17:59:31.659650Z","shell.execute_reply.started":"2025-06-28T17:57:16.066243Z","shell.execute_reply":"2025-06-28T17:59:31.658580Z"}},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.3.160-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.7.2)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.2)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\nRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (7.0.0)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.3)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.0->ultralytics) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\nDownloading ultralytics-8.3.160-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.160 ultralytics-thop-2.0.14\nCreating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.5'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n","output_type":"stream"},{"name":"stdout","text":"Using device: cuda\nDetected 1764 images and 2081 labels.\nStratified splitting failed (The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.), using random split\nDetected 3 classes with distribution: {2: 1603, 0: 1053, 1: 1}\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/2690310958.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m     \u001b[0myaml_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_yaml_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Enhanced model ensemble with more diverse models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'create_yaml_config' is not defined"],"ename":"NameError","evalue":"name 'create_yaml_config' is not defined","output_type":"error"}],"execution_count":3}]}